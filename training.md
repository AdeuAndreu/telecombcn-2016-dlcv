---
layout: page
title: Training Convolutional Neural Networks
permalink: /training
hide: true
---

# Training Convolutional Neural Networks

## Instructor

|  ![Elisa Sayrol][ElisaSayrol-photo]  |
|:-:|:-:|:-:|:-:|:-:|:-:|
| [Elisa Sayrol (ES)][ElisaSayrol-web]  |

[ElisaSayrol-web]: https://imatge.upc.edu/web/people/elisa-sayrol

[ElisaSayrol-photo]: img/instructors/ElisaSayrol.jpg "Elisa Sayrol"

## Slides

(to be added)

## Video lecture

(to be added)



## Related papers

### Back-propagation

* LeCun, Yann, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. ["Gradient-based learning applied to document recognition."](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) Proceedings of the IEEE 86, no. 11 (1998): 2278-2324.

### Drop out
* Hinton, Geoffrey E., Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R. Salakhutdinov. ["Improving neural networks by preventing co-adaptation of feature detectors."](http://arxiv.org/abs/1207.0580) arXiv preprint arXiv:1207.0580 (2012).
* Baldi, Pierre, and Peter J. Sadowski. ["Understanding dropout."](http://papers.nips.cc/paper/4878-understanding-dropout) In Advances in Neural Information Processing Systems, pp. 2814-2822. 2013.
* * Srivastava, Nitish, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. ["Dropout: A simple way to prevent neural networks from overfitting."](http://www.cs.utoronto.ca/~hinton/absps/JMLRdropout.pdf) The Journal of Machine Learning Research 15, no. 1 (2014): 1929-1958.

### Max out
* Goodfellow, I., Warde-farley, D., Mirza, M., Courville, A. and Bengio, Y., 2013. [Maxout Networks](http://www.jmlr.org/proceedings/papers/v28/goodfellow13.pdf). In Proceedings of the 30th International Conference on Machine Learning (ICML-13) (pp. 1319-1327).
